best_params:
  batch_size: 16
  dropout_rate: 0.2219530631494497
  num_layers_to_use: 1
  optimizer_type: adamw
  use_multilayer: false
  weight_decay: 0.04934857784867061
best_value: 0.9488
classifier_type: attention
metric: f1_macro
test_results:
  eval_accuracy: 0.9281
  eval_f1_macro: 0.9262
  eval_loss: 0.5479
  eval_matthews_correlation: 0.9099
  eval_precision: 0.9282
  eval_recall: 0.9251
training_metadata:
  architecture:
    classifier_type: attention
    dropout_rate: 0.2219530631494497
    num_layers_to_use: 1
    use_multilayer: false
  batch_size: 16
  optimizer: adamw
  timestamp: 2025-03-16 13:52:45 GMT+10
